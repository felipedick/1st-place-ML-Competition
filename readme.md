
# 1. Competi√ß√£o da Alura de Fraudes em Transa√ß√µes de Cart√£o de Cr√©dito - Kaggle (04/2024)

## 1.1 **üèÜüèÜ VENCEDOR DA COMPETI√á√ÉO üèÜüèÜ**
O modelo final obteve um score de 99,897%, conquistando o **primeiro lugar** na competi√ß√£o.

![Leaderboard da Competi√ß√£o](./Images/Kaggle%20Leaderboard.PNG)

## 1.2 Link para a Competi√ß√£o:
[Competi√ß√£o Kaggle](https://www.kaggle.com/competitions/fraude-em-transaes-de-carto-de-crdito/overview)

## 1.3 Descri√ß√£o

O objetivo da competi√ß√£o foi prever a probabilidade de uma transa√ß√£o de cart√£o de cr√©dito ser fraudulenta ou n√£o. A competi√ß√£o durou de 30 de janeiro a 5 de abril de 2024, e os participantes receberam datasets para treinar e avaliar seus modelos de Machine Learning.

## 1.4 Contexto
Em 2022, o volume de transa√ß√µes com cart√µes de cr√©dito cresceu cerca de 35%, segundo a ABECS, atingindo R$ 3,31 trilh√µes e movimentando a maioria (52,9%) do consumo das fam√≠lias brasileiras. Isso ressalta a import√¢ncia de detectar fraudes em transa√ß√µes de cart√£o de cr√©dito.

---

# 2. O Projeto

## 2.1 Jupyter Notebook / Google Colab
O projeto foi realizado usando o Google Colab. Voc√™ pode acess√°-lo abaixo

[Abrir](https://github.com/felipedick/1st-place-Machine-Learning-Competittion/blob/main/Alura_Fraud_Transaction_Competition_Award.ipynb)

## 2.2 Bibliotecas Utilizadas
Este projeto utilizou as seguintes bibliotecas:

- `Pandas`
- `Numpy`
- `Plotly`
- `Sklearn`

## 2.3 Coleta dos Dados
Os dados foram disponibilizados atrav√©s da plataforma Kaggle ([link dos dados](https://www.kaggle.com/competitions/fraude-em-transaes-de-carto-de-crdito/data)).

Arquivos coletados:
- **treino.csv.xz** - Arquivo de treino
- **teste.csv.xz** - Arquivo de teste
- **exemplo_submissao.csv** - Exemplo do formato de submiss√£o

Foi realizada uma an√°lise inicial usando `.info()` para entender as vari√°veis dispon√≠veis.

## 2.4 Limpeza dos Dados
A etapa de limpeza dos dados incluiu a remo√ß√£o de colunas irrelevantes ou com muitos valores ausentes. As seguintes vari√°veis foram removidas:

- **merch_lat**, **merch_long**, e **zip**: Alto n√∫mero de valores ausentes (10% do total).
- **ssn**, **cc_num**, **first**, **last**, **street**, **acct_num**, **trans_num**, e **dob**: Dados espec√≠ficos que poderiam causar overfitting.
- **trans_date** e **trans_time**: Utilizou-se o campo **unix_time** para representar o tempo.
- **city** e **state**: Substitu√≠dos pela vari√°vel **population**.
- **merchan**, **lat** e **long**: Considerados pouco relevantes.

Ap√≥s a remo√ß√£o de colunas, tratamos os valores ausentes.

## 2.5 An√°lise Explorat√≥ria dos Dados (EDA)
A EDA teve como foco a deriva√ß√£o de novas vari√°veis e a valida√ß√£o de hip√≥teses de neg√≥cio, al√©m de investigar padr√µes e anomalias nos dados. Dada a limita√ß√£o de tempo, a EDA foi limitada √†s seguintes an√°lises:

- **Distribui√ß√£o da vari√°vel alvo por g√™nero**: Identificado o desbalanceamento de classes (fraude vs n√£o fraude).
- **Boxplot do valor das transa√ß√µes**: Investigamos a hip√≥tese de que transa√ß√µes acima de determinado valor seriam fraudes. A hip√≥tese foi rejeitada, j√° que transa√ß√µes fraudulentas variaram at√© $1264,23, mas houve v√°rias transa√ß√µes n√£o fraudulentas acima desse valor.

## 2.6 Modelagem dos Dados
Nesta etapa, preparamos os dados para o treinamento dos modelos, aplicando t√©cnicas como:

- **OneHotEncoder** para vari√°veis categ√≥ricas.
- **StandardScaler** para normaliza√ß√£o.
- **SMOTE** para lidar com o desbalanceamento de classes.

## 2.7 Aplica√ß√£o de Algoritmos de Machine Learning
Os seguintes modelos de Machine Learning foram aplicados:

- `DummyClassifier`
- `DecisionTreeClassifier`
- `RandomForestClassifier`
- `XGBClassifier`

O **RandomForestClassifier** obteve o melhor desempenho, com uma **acur√°cia de 99,87%** e **precis√£o de 99,88%**.

| Rank | Modelo                    | Acur√°cia  | Precis√£o |
|------|---------------------------|-----------|----------|
| 1    | RandomForest               | 0.9987    | 0.9988   |
| 2    | DecisionTreeClassifier     | 0.9974    | 0.9974   |
| 3    | XGBClassifier              | 0.9625    | 0.9831   |
| 4    | DummyClassifier            | 0.5000    | 0.2499   |

## 2.8 Aplica√ß√£o no Dataset de Teste
O modelo **RandomForestClassifier** foi aplicado no dataset de teste, utilizando o mesmo pr√©-processamento. O arquivo final obteve um score de 99,897%, garantindo o primeiro lugar na competi√ß√£o.

---

# 3. Coment√°rios Gerais
Participar dessa competi√ß√£o foi uma excelente oportunidade de aprendizado. O foco principal foi o desenvolvimento de um modelo funcional dentro de um prazo curto. Ap√≥s a competi√ß√£o, continuei aprimorando t√©cnicas e revisando o projeto para identificar √°reas de melhoria.

---

# 4. Melhorias / Pr√≥ximos Passos

## 4.1 An√°lise e Visualiza√ß√£o dos Dados
Aprimorei a visualiza√ß√£o dos dados utilizando bibliotecas como `ydata-profiling`, `matplotlib` e `seaborn`. Esses gr√°ficos ajudam a identificar padr√µes e outliers de forma mais clara.

## 4.2 Valida√ß√£o Cruzada
Implementar **valida√ß√£o cruzada** como o `StratifiedKFold` garantiria uma avalia√ß√£o mais robusta do modelo, evitando overfitting.

## 4.3 Tunagem de Hiperpar√¢metros
O ajuste fino de hiperpar√¢metros, com t√©cnicas como **GridSearch** e **RandomizedSearch**, pode melhorar ainda mais a performance do modelo.

## 4.4 Pipeline
Criar um **pipeline de machine learning** com o `Pipeline` do `sklearn` automatizaria o processo de transforma√ß√£o de dados e modelagem, garantindo reprodutibilidade e escalabilidade.

## 4.5 Redu√ß√£o de Dimensionalidade
T√©cnicas como **PCA** podem reduzir o n√∫mero de features, simplificando o modelo e melhorando seu desempenho.

## 4.6 Sele√ß√£o de Atributos
Utilizar **feature selection** com base em import√¢ncia de vari√°veis pode reduzir a complexidade do modelo sem perder precis√£o.


# 5. Conecte-se Comigo:
<a href="https://www.linkedin.com/in/felipe-dick" target="_blank">
    <img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" alt="Link" width="30" height="30">    
</a>
<br>
<br>

