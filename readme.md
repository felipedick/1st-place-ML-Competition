
# 1. Competi√ß√£o da Alura de Fraudes em Transa√ß√µes de Cart√£o de Cr√©dito - Kaggle (04/2024)

## 1.1 **üèÜüèÜ VENCEDOR DA COMPETI√á√ÉO üèÜüèÜ**

<br>

<img src="./Images/Kaggle Leaderboard.PNG" width="100%">

## 1.2 Link para a Competi√ß√£o:
[Competi√ß√£o Kaggle](https://www.kaggle.com/competitions/fraude-em-transaes-de-carto-de-crdito/overview)

# 2. Descri√ß√£o

O objetivo da competi√ß√£o era prever a probabilidade de uma transa√ß√£o de cart√£o de cr√©dito ser fraude ou n√£o. A competi√ß√£o durou cerca de 3 meses, de 30 de Janeiro de 2024 a 5 de Abril de 2024. Um dataset foi disponibilizado para treinamento dos modelos de Machine Learning, enquanto outro foi utilizado para avaliar o resultado final.

## 2.1 Contexto
Em 2022, o volume de transa√ß√µes com cart√µes de cr√©dito cresceu cerca de 35%, segundo a ABECS, atingindo R$ 3,31 trilh√µes e movimentando a maioria (52,9%) de todo o consumo das fam√≠lias brasileiras no per√≠odo. Isso mostra a relev√¢ncia de detectar fraudes nas transa√ß√µes de cart√£o de cr√©dito.

## 2.2 Jupyter Notebook
O projeto foi realizado usando o Google Colab. Voc√™ pode acess√°-lo clicando no bot√£o abaixo:

<a href="./Kaggle_Competition_Award.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>

## 2.3 Bibliotecas Utilizadas
Este projeto utiliza as seguintes bibliotecas:

- `Pandas`
- `Numpy`
- `Plotly`
- `Sklearn`

## 2.4 Pr√©-processamento de Dados
Para a utiliza√ß√£o de t√©cnicas de Machine Learning, √© importante realizar o pr√©-processamento dos dados de maneira adequada. Foram utilizadas as seguintes t√©cnicas:

- **OneHotEncoder**
- **make_column_transformer**
- **StandardScaler**
- **SMOTE** (para lidar com classes desbalanceadas)

## 2.5 Modelos Utilizados
Os seguintes modelos de machine learning foram aplicados para a classifica√ß√£o:

- `DummyClassifier`
- `DecisionTreeClassifier`
- `RandomForestClassifier`
- `XGBClassifier`
  
O modelo que apresentou melhor acur√°cia foi o `RandomForestClassifier`, com uma **acur√°cia de 99,8794% e uma precis√£o de 99,885%!**

| Rank | Model                    | Accuracy  | Precision |
|------|--------------------------|-----------|-----------|
| 1    | RandomForest             | 0.9987  | 0.9988  |
| 2    | DecisionTreeClassifier    | 0.9974  | 0.9974  |
| 3    | XGBClassifier            | 0.9625  | 0.9831  |
| 4    | DummyClassifier          | 0.5000  | 0.2499  |

## 2.6 Coment√°rios Gerais
Participar da competi√ß√£o foi uma oportunidade valiosa de aprendizado, onde o foco principal foi no desenvolvimento de um modelo funcional, considerando o tempo reduzido. Com o t√©rmino, dediquei tempo a aprimorar t√©cnicas e revisar o trabalho com mais calma, o que me levou √†s sugest√µes de melhorias descritas abaixo.

# 3. Melhorias / Pr√≥ximos Passos
Com base na experi√™ncia adquirida durante a competi√ß√£o, identifiquei diversas √°reas para aprimoramento que podem contribuir para o desenvolvimento de modelos de machine learning mais robustos e eficientes.

## 3.1 An√°lise e Visualiza√ß√£o dos Dados 
√â poss√≠vel aprimorar a visualiza√ß√£o dos dados, criando gr√°ficos mais informativos que destacam padr√µes e outliers. Isso ajuda a entender a distribui√ß√£o dos dados e as rela√ß√µes entre vari√°veis, facilitando insights mais profundos. Um exemplo √© a aplica√ß√£o do m√≥dulo `ydata-profiling` e da biblioteca `ProfileReport`. Al√©m disso, bibliotecas como `matplotlib` e `seaborn` podem ser utilizadas para criar visualiza√ß√µes personalizadas que atendam a necessidades espec√≠ficas.

## 3.2 Valida√ß√£o Cruzada
Implementar valida√ß√£o cruzada garante que o modelo seja avaliado de forma robusta. Isso evita o overfitting, ao testar o desempenho do modelo em diferentes subconjuntos dos dados e assegurando uma avalia√ß√£o mais realista. Uma abordagem como `StratifiedKFold` pode ser utilizada para garantir a representa√ß√£o adequada das classes.

## 3.3 Hiperpar√¢metros
O ajuste fino de hiperpar√¢metros pode melhorar significativamente a performance do modelo. Automatizar o processo de busca pelos melhores valores usando t√©cnicas como `GridSearch`, `RandomizedSearch` ou at√© mesmo `Bayesian Optimization` pode levar a resultados mais otimizados.

## 3.4 Pipeline
A cria√ß√£o de um pipeline de machine learning automatiza o processo de transforma√ß√£o de dados e modelagem, garantindo reprodutibilidade e escalabilidade, facilitando tamb√©m a manuten√ß√£o ao longo do tempo. O uso do `Pipeline` do `sklearn` pode ser um exemplo pr√°tico dessa implementa√ß√£o.

## 3.5 Redu√ß√£o de Dimensionalidade
A aplica√ß√£o de t√©cnicas como PCA pode reduzir o n√∫mero de features no conjunto de dados, simplificando o modelo e melhorando o desempenho, especialmente em datasets com muitas vari√°veis correlacionadas. Alternativas como t-SNE ou UMAP tamb√©m podem ser consideradas para visualiza√ß√µes mais eficazes.

## 3.6 Sele√ß√£o de Atributos
Implementar t√©cnicas de sele√ß√£o de atributos, como `SelectKBest` ou `Recursive Feature Elimination`, permite identificar as vari√°veis mais relevantes, reduzindo a complexidade do modelo e aumentando a interpretabilidade sem perda significativa de precis√£o. Al√©m disso, t√©cnicas baseadas em modelos, como Lasso, podem ser utilizadas para sele√ß√£o e regulariza√ß√£o.

# 4. Conecte-se Comigo:
<a href="https://www.linkedin.com/in/felipe-dick" target="_blank">
    <img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" alt="Link" width="30" height="30">    
</a>
<br>
<br>

