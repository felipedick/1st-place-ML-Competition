# Alura Kaggle competitition for fraud transaction in April/24

## **ğŸ†ğŸ† AWARD 1ST PLACE ğŸ†ğŸ†**
## **ğŸ†ğŸ† VENCEDOR DA COMPETIÃ‡ÃƒO ğŸ†ğŸ†**


<br>

<img src="./Images/Kaggle Leaderboard.PNG" width="100%">


## Link to Competition / Link para competiÃ§Ã£o:
[https://www.kaggle.com/competitions/fraude-em-transaes-de-carto-de-crdito/code](https://www.kaggle.com/competitions/fraude-em-transaes-de-carto-de-crdito/overview)

## Description / DescriÃ§Ã£oo:
The goal of the competition is to predict whether a credit card transaction is fraudulent or not. The competition lasted for three months, from January 30, 2024, to April 5, 2024.

O objetivo da competiÃ§Ã£o era prever qual a probablidade de uma transaÃ§Ã£o de cartÃ£o de crÃ©dito ser fraude ou nÃ£o. A competiÃ§Ã£o durou cerca de 3 meses, de 30 de Janeiro de 2024 a 5 de Abril de 2024. Foi disponibilizado um dataset para treinamento dos modelos de Machine Learning e um dataset com amostras que foram utilizadas para avaliar o resultado final.

### Contexto
Em 2022, o volume de transaÃ§Ãµes com cartÃµes de crÃ©dito cresceu cerca de 35%, segundo a ABECS, atingindo  R$ 3,31 trilhÃµes e movimentando a maioria (52,9%)de todo o consumo das famÃ­lias brasileiras no perÃ­odo. (AssociaÃ§Ã£o Brasileira das Empresas de CartÃµes de CrÃ©dito e ServiÃ§os).

## Jupyter Notebook
The project was designed using Google Colab.

O Projeto foi feito usando o Google Colab.

<a href="./Kaggle_Competition_Award.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>

### Bibliotecas utilizadas
This project used the following library:

Este projeto utiliza as seguintes bibliotecas

- `Pandas`
- `Numpy`
- `Plotly`
- `Sklearn`

### PrÃ©-processamento de Dados
Os dados foram prÃ©-processados utilizando as seguintes tÃ©cnicas:

- **OneHotEncoder**
- **make_column_transformer**
- **StandardScaler**
- **SMOTE** (para lidar com classes desbalanceadas)

### Modelos Utilizados
Os seguintes modelos de machine learning foram aplicados para a classificaÃ§Ã£o:

- `DummyClassifier`
- `DecisionTreeClassifier`
- `RandomForestClassifier`
- `XGBClassifier`
  
O modelo que apresentou melhor acurÃ¡cia foi o RandomForestClassifier com uma **acurÃ¡cia de 99,8794% e uma precisÃ£o de 99,885%!**

| Rank | Model                    | Accuracy  | Precision |
|------|--------------------------|-----------|-----------|
| 1    | RandomForest             | 0.9987  | 0.9988  |
| 2    | DecisionTreeClassifier    | 0.9974  | 0.9974  |
| 3    | XGBClassifier            | 0.9625  | 0.9831  |
| 4    | DummyClassifier          | 0.5000  | 0.2499  |


## Connect with author:

<a href="https://www.linkedin.com/in/felipe-dick" target="_blank">
    <img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" alt="Link" width="30" height="30">    
</a>
<br>
<br>
